import cv2  # OpenCV: ì˜ìƒ ì²˜ë¦¬ ë° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np  # NumPy: ìˆ˜ì¹˜ ê³„ì‚° ë° ë°°ì—´ ì²˜ë¦¬
import os  # OS ê´€ë ¨ ê¸°ëŠ¥ (í´ë” ìƒì„± ë“±)
from ultralytics import YOLO  # YOLOv8 ëª¨ë¸ ë¡œë”© ë¼ì´ë¸ŒëŸ¬ë¦¬
from scipy.spatial.distance import cdist  # scipy ê±°ë¦¬ í–‰ë ¬ í•¨ìˆ˜ (cdist = "cross distance")
import models

# ğŸš¨ ê±°ë¦¬ ì„ê³„ê°’ ì„¤ì • (í”½ì…€ ë‹¨ìœ„) â†’ ì´ ê°’ë³´ë‹¤ ê°€ê¹Œìš°ë©´ ê±°ë¦¬ ìœ„ë°˜ìœ¼ë¡œ íŒë‹¨
DISTANCE_THRESHOLD = 300

# ğŸ¯ YOLOv8 ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model = YOLO("models/PersonDet_v3.2.0.pt")  

# ğŸ¥ VideoCapture ê°ì²´ ìƒì„± (ì¤„ì—¬ì„œ capì´ë¼ ë¶€ë¦„)
# cap = captureì˜ ì•½ì. í”„ë ˆì„ ë‹¨ìœ„ë¡œ ì˜ìƒì„ ì½ëŠ” ê°ì²´
cap = cv2.VideoCapture("blurred_output.mp4")

# ğŸ’¾ ì˜ìƒ ì €ì¥ ì¤€ë¹„
# fourcc = four character code (ë¹„ë””ì˜¤ ì½”ë± ì‹ë³„ì)
fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # mp4 í˜•ì‹ìš© ì½”ë± ì§€ì •
fps = cap.get(cv2.CAP_PROP_FPS) or 30.0  # ì˜ìƒ í”„ë ˆì„ ì†ë„ (ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   # í”„ë ˆì„ ê°€ë¡œ ë„ˆë¹„
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # í”„ë ˆì„ ì„¸ë¡œ ë†’ì´

# ì¶œë ¥ í´ë” ìƒì„± (ì´ë¯¸ ìˆìœ¼ë©´ ë¬´ì‹œ)
os.makedirs("output", exist_ok=True)

# ğŸ¬ ë¹„ë””ì˜¤ ì €ì¥ ê°ì²´ ìƒì„±
# out = ì¶œë ¥ ë¹„ë””ì˜¤ ê°ì²´ (VideoWriter)
out = cv2.VideoWriter("output/result.mp4", fourcc, fps, (width, height))

# ğŸï¸ ì˜ìƒ í”„ë ˆì„ ì²˜ë¦¬ ë£¨í”„ ì‹œì‘
while cap.isOpened():
    ret, frame = cap.read()  # ret: ì„±ê³µ ì—¬ë¶€ (True/False), frame: í˜„ì¬ í”„ë ˆì„ ì´ë¯¸ì§€
    if not ret:
        break  # ì˜ìƒ ëë‚¬ê±°ë‚˜ ì˜¤ë¥˜ ì‹œ ë£¨í”„ ì¢…ë£Œ

    results = model(frame)[0]  # YOLOv8ìœ¼ë¡œ íƒì§€ ì‹¤í–‰ (ì²« ë²ˆì§¸ ê²°ê³¼ ê°€ì ¸ì˜´)
    centers = []  # ì‚¬ëŒ ì¤‘ì‹¬ ì¢Œí‘œë“¤ ì €ì¥ ë¦¬ìŠ¤íŠ¸ (cx, cy)
    boxes = []    # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì €ì¥ ë¦¬ìŠ¤íŠ¸ [(x1, y1, x2, y2)]

    # ğŸ‘¤ ì‚¬ëŒë§Œ í•„í„°ë§ (COCO class ID 0 = person)
    for box in results.boxes:
        if int(box.cls[0]) == 0:
            x1, y1, x2, y2 = box.xyxy[0].tolist()  # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
            cx = int((x1 + x2) / 2)  # ì¤‘ì‹¬ì  x
            cy = int((y1 + y2) / 2)  # ì¤‘ì‹¬ì  y
            centers.append((cx, cy))  # ì¤‘ì‹¬ì  ì €ì¥
            boxes.append((int(x1), int(y1), int(x2), int(y2)))  # ë°•ìŠ¤ ì €ì¥

    centers = np.array(centers)  # ê±°ë¦¬ ê³„ì‚°ì„ ìœ„í•´ numpy ë°°ì—´ë¡œ ë³€í™˜

    # âœ… ëª¨ë“  ì‚¬ëŒì—ê²Œ ì´ˆë¡ ë°•ìŠ¤ ë¨¼ì € ê·¸ë¦¼
    for box in boxes:
        cv2.rectangle(frame, box[:2], box[2:], (0, 255, 0), 2)  # ì´ˆë¡ ë°•ìŠ¤

    # ğŸ“ ì‚¬ëŒ ê°„ ê±°ë¦¬ ê³„ì‚° (N x N ê±°ë¦¬ í–‰ë ¬)
    if len(centers) >= 2:
        # cdist: centerë“¤ ê°„ì˜ ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ ê³„ì‚°
        dist_matrix = cdist(centers, centers, metric='euclidean')

        # ğŸ”´ ê±°ë¦¬ ìœ„ë°˜ ì‹œê°í™”: ê°€ê¹Œìš´ ìŒë§Œ ë¹¨ê°„ ì„ /ê±°ë¦¬ í‘œì‹œ
        for i in range(len(centers)):
            for j in range(i + 1, len(centers)):  # ì¤‘ë³µ ë°©ì§€: (i < j)
                if dist_matrix[i][j] < DISTANCE_THRESHOLD:
                    p1 = tuple(centers[i].astype(int))  # ì²« ë²ˆì§¸ ì‚¬ëŒ ìœ„ì¹˜
                    p2 = tuple(centers[j].astype(int))  # ë‘ ë²ˆì§¸ ì‚¬ëŒ ìœ„ì¹˜
                    cv2.line(frame, p1, p2, (0, 0, 255), 2)  # ë¹¨ê°„ ì„  ê·¸ë¦¬ê¸°
                    cv2.putText(frame, f"{int(dist_matrix[i][j])}px", p1,
                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)  # ê±°ë¦¬ ìˆ«ì ì¶œë ¥

    # ğŸ“ í”„ë ˆì„ ì €ì¥ (output/result.mp4ì— ê¸°ë¡ë¨)
    out.write(frame)

# ğŸ§¹ ìì› ì •ë¦¬
cap.release()  # ìº¡ì²˜ ì¢…ë£Œ
out.release()  # ë¹„ë””ì˜¤ ì €ì¥ ì¢…ë£Œ
print("ğŸ¬ ì˜ìƒ ì €ì¥ ì™„ë£Œ! â†’ output/result.mp4")
